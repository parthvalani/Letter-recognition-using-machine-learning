{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vbwjG5VLF_MF",
    "outputId": "5219e85b-62c0-4560-99e2-2ec7bcf989d2"
   },
   "outputs": [],
   "source": [
    "######## import all libraries #########\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,scale\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras import activations\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 16) (20000, 26)\n"
     ]
    }
   ],
   "source": [
    "######## Load Dataset ##########\n",
    "path = 'letter-recognition.txt'\n",
    "# read .txt file using pandas.\n",
    "data=pd.read_csv(path)\n",
    "# last 16 colomnn as a inputs\n",
    "X=data.iloc[:,1:]\n",
    "# first column as a labels.\n",
    "Y=data.iloc[:,0]\n",
    "# total number of classes\n",
    "classes = len(np.unique(Y))\n",
    "# convert inputs in the range of 0 to 1.\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "# convert letter type labels into numeric type( 0 to 25)\n",
    "Y = LabelEncoder().fit_transform(Y)\n",
    "# convert labels into one-hot encode respresntation. if label=2 then [0 0 1....0]\n",
    "Y = to_categorical(Y,classes)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### train test split ##############\n",
    "# 70 % training and 30% testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Sy2Mq23cwlzA",
    "outputId": "08f1ba77-4bd8-4bbf-af45-a9ea5707a2be",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 300)               5100      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "feature (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 26)                3926      \n",
      "=================================================================\n",
      "Total params: 54,176\n",
      "Trainable params: 54,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.9935 - accuracy: 0.2017 - val_loss: 2.4076 - val_accuracy: 0.3495\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.1474 - accuracy: 0.4034 - val_loss: 1.7358 - val_accuracy: 0.5128\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.6872 - accuracy: 0.5134 - val_loss: 1.4506 - val_accuracy: 0.5905\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.4533 - accuracy: 0.5745 - val_loss: 1.2807 - val_accuracy: 0.6290\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3039 - accuracy: 0.6179 - val_loss: 1.1651 - val_accuracy: 0.6598\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1890 - accuracy: 0.6553 - val_loss: 1.0636 - val_accuracy: 0.6915\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1070 - accuracy: 0.6786 - val_loss: 0.9840 - val_accuracy: 0.7292\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0365 - accuracy: 0.6977 - val_loss: 0.9295 - val_accuracy: 0.7542\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9641 - accuracy: 0.7227 - val_loss: 0.8630 - val_accuracy: 0.7642\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9123 - accuracy: 0.7364 - val_loss: 0.8373 - val_accuracy: 0.7608\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8703 - accuracy: 0.7424 - val_loss: 0.7887 - val_accuracy: 0.7720\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8280 - accuracy: 0.7545 - val_loss: 0.7469 - val_accuracy: 0.7882\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7860 - accuracy: 0.7628 - val_loss: 0.7093 - val_accuracy: 0.7992\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7581 - accuracy: 0.7708 - val_loss: 0.6815 - val_accuracy: 0.8025\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7273 - accuracy: 0.7788 - val_loss: 0.6756 - val_accuracy: 0.7957\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7028 - accuracy: 0.7844 - val_loss: 0.6183 - val_accuracy: 0.8283\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6641 - accuracy: 0.7988 - val_loss: 0.5886 - val_accuracy: 0.8348\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6277 - accuracy: 0.8103 - val_loss: 0.5681 - val_accuracy: 0.8360\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6022 - accuracy: 0.8159 - val_loss: 0.5485 - val_accuracy: 0.8430\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.8208 - val_loss: 0.5390 - val_accuracy: 0.8400\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5625 - accuracy: 0.8243 - val_loss: 0.5128 - val_accuracy: 0.8488\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5456 - accuracy: 0.8311 - val_loss: 0.4731 - val_accuracy: 0.8673\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.8373 - val_loss: 0.4741 - val_accuracy: 0.8550\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.8452 - val_loss: 0.4619 - val_accuracy: 0.8583\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.8470 - val_loss: 0.4376 - val_accuracy: 0.8735\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.8511 - val_loss: 0.4145 - val_accuracy: 0.8745\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.8585 - val_loss: 0.3985 - val_accuracy: 0.8842\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4468 - accuracy: 0.8616 - val_loss: 0.3985 - val_accuracy: 0.8798\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.8633 - val_loss: 0.3812 - val_accuracy: 0.8890\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8654 - val_loss: 0.3802 - val_accuracy: 0.8825\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8687 - val_loss: 0.3665 - val_accuracy: 0.8910\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8719 - val_loss: 0.3612 - val_accuracy: 0.8885\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8754 - val_loss: 0.3460 - val_accuracy: 0.8940\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8744 - val_loss: 0.3393 - val_accuracy: 0.8997\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8845 - val_loss: 0.3268 - val_accuracy: 0.8978\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8909 - val_loss: 0.3120 - val_accuracy: 0.9015\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8884 - val_loss: 0.3083 - val_accuracy: 0.9038\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3508 - accuracy: 0.8882 - val_loss: 0.3134 - val_accuracy: 0.9060\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3416 - accuracy: 0.8909 - val_loss: 0.3048 - val_accuracy: 0.9018\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8956 - val_loss: 0.2979 - val_accuracy: 0.9075\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.8938 - val_loss: 0.2879 - val_accuracy: 0.9123\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3183 - accuracy: 0.8994 - val_loss: 0.2828 - val_accuracy: 0.9122\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3123 - accuracy: 0.9031 - val_loss: 0.2751 - val_accuracy: 0.9133\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3052 - accuracy: 0.9012 - val_loss: 0.2692 - val_accuracy: 0.9173\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2969 - accuracy: 0.9064 - val_loss: 0.2678 - val_accuracy: 0.9147\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2900 - accuracy: 0.9097 - val_loss: 0.2650 - val_accuracy: 0.9162\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2955 - accuracy: 0.9084 - val_loss: 0.2612 - val_accuracy: 0.9168\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2930 - accuracy: 0.9071 - val_loss: 0.2548 - val_accuracy: 0.9187\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2795 - accuracy: 0.9106 - val_loss: 0.2402 - val_accuracy: 0.9238\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2789 - accuracy: 0.9095 - val_loss: 0.2394 - val_accuracy: 0.9293\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2699 - accuracy: 0.9136 - val_loss: 0.2469 - val_accuracy: 0.9215\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.9102 - val_loss: 0.2378 - val_accuracy: 0.9273\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2728 - accuracy: 0.9144 - val_loss: 0.2274 - val_accuracy: 0.9293\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2655 - accuracy: 0.9149 - val_loss: 0.2258 - val_accuracy: 0.9300\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2555 - accuracy: 0.9177 - val_loss: 0.2195 - val_accuracy: 0.9333\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2404 - accuracy: 0.9255 - val_loss: 0.2158 - val_accuracy: 0.9303\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2374 - accuracy: 0.9245 - val_loss: 0.2095 - val_accuracy: 0.9347\n",
      "Epoch 58/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2341 - accuracy: 0.9279 - val_loss: 0.2116 - val_accuracy: 0.9318\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2361 - accuracy: 0.9235 - val_loss: 0.2032 - val_accuracy: 0.9350\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2285 - accuracy: 0.9273 - val_loss: 0.2060 - val_accuracy: 0.9340\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2287 - accuracy: 0.9281 - val_loss: 0.2050 - val_accuracy: 0.9360\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9279 - val_loss: 0.2148 - val_accuracy: 0.9312\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2285 - accuracy: 0.9264 - val_loss: 0.1992 - val_accuracy: 0.9347\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2235 - accuracy: 0.9281 - val_loss: 0.1933 - val_accuracy: 0.9397\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2169 - accuracy: 0.9297 - val_loss: 0.1896 - val_accuracy: 0.9390\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2114 - accuracy: 0.9324 - val_loss: 0.1972 - val_accuracy: 0.9380\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2131 - accuracy: 0.9303 - val_loss: 0.1908 - val_accuracy: 0.9395\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2084 - accuracy: 0.9353 - val_loss: 0.1841 - val_accuracy: 0.9422\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2091 - accuracy: 0.9314 - val_loss: 0.1803 - val_accuracy: 0.9433\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1998 - accuracy: 0.9354 - val_loss: 0.1725 - val_accuracy: 0.9463\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1981 - accuracy: 0.9368 - val_loss: 0.1725 - val_accuracy: 0.9460\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1930 - accuracy: 0.9373 - val_loss: 0.1759 - val_accuracy: 0.9415\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1935 - accuracy: 0.9376 - val_loss: 0.1773 - val_accuracy: 0.9413\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1963 - accuracy: 0.9376 - val_loss: 0.1756 - val_accuracy: 0.9460\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1874 - accuracy: 0.9381 - val_loss: 0.1775 - val_accuracy: 0.9412\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1854 - accuracy: 0.9406 - val_loss: 0.1751 - val_accuracy: 0.9428\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1815 - accuracy: 0.9434 - val_loss: 0.1685 - val_accuracy: 0.9472\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1802 - accuracy: 0.9434 - val_loss: 0.1821 - val_accuracy: 0.9410\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1867 - accuracy: 0.9402 - val_loss: 0.1634 - val_accuracy: 0.9488\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1736 - accuracy: 0.9448 - val_loss: 0.1613 - val_accuracy: 0.9468\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1665 - accuracy: 0.9481 - val_loss: 0.1543 - val_accuracy: 0.9490\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1709 - accuracy: 0.9451 - val_loss: 0.1637 - val_accuracy: 0.9478\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1736 - accuracy: 0.9452 - val_loss: 0.1566 - val_accuracy: 0.9507\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1656 - accuracy: 0.9475 - val_loss: 0.1500 - val_accuracy: 0.9515\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1641 - accuracy: 0.9479 - val_loss: 0.1561 - val_accuracy: 0.9467\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1673 - accuracy: 0.9461 - val_loss: 0.1642 - val_accuracy: 0.9450\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1682 - accuracy: 0.9436 - val_loss: 0.1519 - val_accuracy: 0.9507\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1620 - accuracy: 0.9477 - val_loss: 0.1494 - val_accuracy: 0.9540\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1585 - accuracy: 0.9488 - val_loss: 0.1460 - val_accuracy: 0.9518\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1631 - accuracy: 0.9471 - val_loss: 0.1481 - val_accuracy: 0.9523\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1552 - accuracy: 0.9508 - val_loss: 0.1468 - val_accuracy: 0.9512\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.9492 - val_loss: 0.1490 - val_accuracy: 0.9535\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.9481 - val_loss: 0.1395 - val_accuracy: 0.9538\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9524 - val_loss: 0.1501 - val_accuracy: 0.9507\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9537 - val_loss: 0.1433 - val_accuracy: 0.9542\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1452 - accuracy: 0.9519 - val_loss: 0.1374 - val_accuracy: 0.9530\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 0.9541 - val_loss: 0.1375 - val_accuracy: 0.9543\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1428 - accuracy: 0.9559 - val_loss: 0.1339 - val_accuracy: 0.9567\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.9537 - val_loss: 0.1360 - val_accuracy: 0.9567\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.9529 - val_loss: 0.1289 - val_accuracy: 0.9588\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1381 - accuracy: 0.9557 - val_loss: 0.1409 - val_accuracy: 0.9543\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9526 - val_loss: 0.1300 - val_accuracy: 0.9577\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1352 - accuracy: 0.9565 - val_loss: 0.1270 - val_accuracy: 0.9593\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1257 - accuracy: 0.9588 - val_loss: 0.1273 - val_accuracy: 0.9593\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1274 - accuracy: 0.9586 - val_loss: 0.1303 - val_accuracy: 0.9583\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1265 - accuracy: 0.9589 - val_loss: 0.1267 - val_accuracy: 0.9575\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1324 - accuracy: 0.9549 - val_loss: 0.1252 - val_accuracy: 0.9583\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1264 - accuracy: 0.9591 - val_loss: 0.1270 - val_accuracy: 0.9577\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1289 - accuracy: 0.9567 - val_loss: 0.1200 - val_accuracy: 0.9608\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1192 - accuracy: 0.9611 - val_loss: 0.1209 - val_accuracy: 0.9595\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1218 - accuracy: 0.9606 - val_loss: 0.1249 - val_accuracy: 0.9580\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1247 - accuracy: 0.9584 - val_loss: 0.1229 - val_accuracy: 0.9610\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1226 - accuracy: 0.9601 - val_loss: 0.1229 - val_accuracy: 0.9592\n",
      "Epoch 114/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9604 - val_loss: 0.1189 - val_accuracy: 0.9608\n",
      "Epoch 115/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9583 - val_loss: 0.1176 - val_accuracy: 0.9610\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.9631 - val_loss: 0.1157 - val_accuracy: 0.9615\n",
      "Epoch 117/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9608 - val_loss: 0.1168 - val_accuracy: 0.9615\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1213 - accuracy: 0.9604 - val_loss: 0.1252 - val_accuracy: 0.9597\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9604 - val_loss: 0.1215 - val_accuracy: 0.9593\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1169 - accuracy: 0.9619 - val_loss: 0.1140 - val_accuracy: 0.9612\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.9642 - val_loss: 0.1175 - val_accuracy: 0.9632\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1175 - accuracy: 0.9602 - val_loss: 0.1125 - val_accuracy: 0.9642\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1192 - accuracy: 0.9588 - val_loss: 0.1199 - val_accuracy: 0.9600\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9622 - val_loss: 0.1174 - val_accuracy: 0.9602\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.9628 - val_loss: 0.1172 - val_accuracy: 0.9595\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1142 - accuracy: 0.9629 - val_loss: 0.1115 - val_accuracy: 0.9630\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.9641 - val_loss: 0.1132 - val_accuracy: 0.9635\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1068 - accuracy: 0.9636 - val_loss: 0.1109 - val_accuracy: 0.9610\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1091 - accuracy: 0.9638 - val_loss: 0.1124 - val_accuracy: 0.9627\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1084 - accuracy: 0.9644 - val_loss: 0.1150 - val_accuracy: 0.9612\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1025 - accuracy: 0.9666 - val_loss: 0.1101 - val_accuracy: 0.9633\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9642 - val_loss: 0.1179 - val_accuracy: 0.9627\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 0.9627 - val_loss: 0.1179 - val_accuracy: 0.9613\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.9633 - val_loss: 0.1148 - val_accuracy: 0.9622\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1022 - accuracy: 0.9683 - val_loss: 0.1112 - val_accuracy: 0.9632\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 0.9641 - val_loss: 0.1103 - val_accuracy: 0.9637\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.9651 - val_loss: 0.1094 - val_accuracy: 0.9635\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9683 - val_loss: 0.1117 - val_accuracy: 0.9625\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0981 - accuracy: 0.9676 - val_loss: 0.1099 - val_accuracy: 0.9650\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0966 - accuracy: 0.9671 - val_loss: 0.1048 - val_accuracy: 0.9635\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9689 - val_loss: 0.1074 - val_accuracy: 0.9630\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0972 - accuracy: 0.9687 - val_loss: 0.1057 - val_accuracy: 0.9648\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0928 - accuracy: 0.9692 - val_loss: 0.1112 - val_accuracy: 0.9620\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0956 - accuracy: 0.9684 - val_loss: 0.1067 - val_accuracy: 0.9630\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 0.9689 - val_loss: 0.0969 - val_accuracy: 0.9683\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9708 - val_loss: 0.0972 - val_accuracy: 0.9678\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0879 - accuracy: 0.9704 - val_loss: 0.0990 - val_accuracy: 0.9670\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9706 - val_loss: 0.1083 - val_accuracy: 0.9653\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9664 - val_loss: 0.1010 - val_accuracy: 0.9648\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0972 - accuracy: 0.9686 - val_loss: 0.1081 - val_accuracy: 0.9627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e274aa8f40>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################ feature-extraction(ANN model) #############\n",
    "dim = X.shape[1]\n",
    "# building custom model using keras\n",
    "model = Sequential()\n",
    "# first hidden layer with 300 nodes\n",
    "model.add(Dense(300,activation='relu',input_shape=(dim,)))\n",
    "# disable 20% of the nodes to reduce overfitting.\n",
    "model.add(Dropout(0.2))\n",
    "# first hidden layer with 150nodes\n",
    "model.add(Dense(150,name=\"feature\",activation='relu'))\n",
    "# last layers with total classes.\n",
    "model.add(Dense(classes,activation='softmax'))\n",
    "model.summary()\n",
    "# compile the model using these parameters.\n",
    "model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(lr=0.01),metrics=['accuracy'])\n",
    "# fit the model for training with perticular setup of the parameter.\n",
    "model.fit(X_train,Y_train,batch_size=2096, epochs=150,verbose=1,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### extract the features from an intemediate layers ##########\n",
    "# generate new model from the above model with the output layer of the hidden layer.\n",
    "extract = Model(model.inputs, model.get_layer('feature').output)\n",
    "# predict the training and testing data. Generate new features.\n",
    "features1 = extract.predict(X_train)\n",
    "features2 = extract.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### scaling the data ###############\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaling the training/teting data into range of 0 to 1.\n",
    "features1 = scaler.fit_transform(features1)\n",
    "features2 = scaler.transform(features2)\n",
    "# convert back to the original labels.\n",
    "y_train = np.argmax(Y_train, axis=-1)\n",
    "y_test = np.argmax(Y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "saJLWpWuMYyG",
    "outputId": "7a86708b-2f75-4a89-ebf8-dd78d80a6178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score: 97.55\n"
     ]
    }
   ],
   "source": [
    "######### SVM classifier ##########\n",
    "from sklearn.svm import SVC\n",
    "# SVC classifier using 'rbf' kernel because multi-label classes with perticular parameter after hyper-tuning.\n",
    "model = SVC(C=1000, gamma=0.01,kernel='rbf')\n",
    "model.fit(features1,y_train)\n",
    "score = model.score(features2, y_test)\n",
    "print(\"SVM score:\",score*100)\n",
    "#print(\"accuracy :\", accuracy_score(y_pred,y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 97.16666666666667\n"
     ]
    }
   ],
   "source": [
    "######## KNN classifier ##########\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(features1, y_train)\n",
    "acc = neigh.score(features2, y_test)\n",
    "print(\"KNN score:\",acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic Regression score: 94.33333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valan\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "######### Logistic Regression ########\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(features1,y_train)\n",
    "score = model.score(features2, y_test)\n",
    "print(\"logistic Regression score:\",score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score: 86.21666666666667\n"
     ]
    }
   ],
   "source": [
    "######## DecisionTree Classifier #########\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(features1,y_train)\n",
    "score = model.score(features2, y_test)\n",
    "print(\"Decision Tree score:\",score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes score: 77.55\n"
     ]
    }
   ],
   "source": [
    "######## Naive bayes Classifier #########\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(features1,y_train)\n",
    "score = model.score(features2, y_test)\n",
    "print(\"Naive bayes score:\",score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score: 96.78333333333333\n"
     ]
    }
   ],
   "source": [
    "######## RF Classifier #########\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(features1,y_train)\n",
    "score = model.score(features2, y_test)\n",
    "print(\"Random Forest score:\",score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELM score: 98.31666666666666\n"
     ]
    }
   ],
   "source": [
    "######## ELM classifier ##########\n",
    "from sklearn_extensions.extreme_learning_machines.elm import GenELMClassifier\n",
    "from sklearn_extensions.extreme_learning_machines.random_layer import RBFRandomLayer, MLPRandomLayer\n",
    "clf = GenELMClassifier(hidden_layer=MLPRandomLayer(n_hidden=5000, activation_func='tanh')) \n",
    "clf.fit(features1, y_train)\n",
    "res = clf.score(features2, y_test)\n",
    "print(\"ELM score:\",res*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
